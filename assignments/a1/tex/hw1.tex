% --------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% --------------------------------------------------------------

\documentclass[12pt]{article}


\usepackage[margin=1in]{geometry} 
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{multirow}
\usepackage{amsmath,amsthm,amssymb}
\usepackage[procnames]{listings}
\usepackage{float}
\usepackage{color}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}

\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\begin{document}

% --------------------------------------------------------------
%                         Start here
% --------------------------------------------------------------

\title{Assignment 1}%replace X with the appropriate number
\author{Kelvin Xu\\ %replace with your name
COMP652} %if necessary, replace with your course title

\maketitle
\begin{problem}{1. (a)}
See function load\_data
\end{problem}

\begin{problem}{1. (b)}
With each datacase as a row
\end{problem}
\begin{align*}
    Xw &= Y 
\end{align*}
By doing this, we can see that we are not changing any of the decision
boundaries. We are just are only effecting the regression coefficients, and
their corresponding intepretation. This approach also has the added advantage
that it can help avoid numerical instabilities.

Finally, normalization of this type, and other similar normalization schemes
helps make the model invariant to parameterization. For example, the ridge
regression classifier will have very different weights for the same data
shifted around because the penalty will shrink the weight matrix
often at the expense of accuracy. 

\begin{problem}{1. (c)}
See function polyRegress 
\end{problem}

\begin{problem}{1. (d)}
See function cross\_valid\_regress 
\end{problem}

\begin{problem}{1. (e)}
Writing out the complete table, see cross\_valid\_regress
for code that produced results.
\end{problem}

\begin{center}
\begin{tabular}{ |l|l|l|l| }
\hline
\multicolumn{4}{ |c| }{Team sheet} \\
\hline
Value of d & Training Error & Test Error & Mean/Standard Dev\\ \hline
\multirow{4}{*}{d = 1} & - & - & - \\
 & - & - & - \\
 & - & - & - \\
 & - & - & - \\
 & - & - & - \\ \hline
\multirow{4}{*}{d = 2} & - & - & - \\
 & - &- & - \\
 & - &- & - \\
 & - &- & - \\
 & - &- & - \\ \hline
\multirow{4}{*}{d = 3} & - & - & - \\
 & - & - & - \\
 & - & - & - \\
 & - & - & - \\
 & - & - & - \\ \hline
\multirow{4}{*}{d = 4} & - & - & - \\
 & - & - & - \\
 & - & - & - \\
 & - & - & - \\
 & - & - & - \\ \hline
\multirow{4}{*}{d = 5} & - & - & - \\
 & - & - & - \\
 & - & - & - \\
 & - & - & - \\
 & - & - & - \\ \hline
\end{tabular}
\end{center}

\begin{problem}{1. (f)}
TODO, plot graph
\end{problem}

\begin{problem}{2.}
Writing out the log-likelihood:
\end{problem}
\[
    L = \prod_{i=1}^{m} P(y_i \mid x_i ; h ) P(x_i)
\]
We are interested in the argmax of this value, we 
also can take a log which doesn't change the argmax since log
is a monotonically increasing function.
\begin{align*}
    \argmax_w L &= \argmax \log l \\
    l &= \sum_{i=1}^{m} \log P(y_i \mid x_i ; w ) + \log P(x_i)
\end{align*}
Discarding the $P(x_i)$ term since it does not depend on w.
\begin{align*}
    l &= \sum_{i=1}^{m} \log P(y_i \mid x_i ; w ) \\
      &= \sum_{i=1}^{m} \log \Bigg( \frac{1}{\sqrt{2\pi\sigma_i^2}} \exp \Big(-\frac{1}{2} \frac{(y_i - h_w(x_i))^2}{\sigma_i^2} \Big) \Bigg) \\ 
      &= \sum_{i=1}^{m} \log \Big( \frac{1}{\sqrt{2\pi\sigma_i^2}} \Big) - \sum_{i=1}^{m} \Big(\frac{1}{2} \frac{(y_i - h_w(x_i))^2}{\sigma_i^2} \Big)
\end{align*}
Dropping the first term since it has no dependence on w
\begin{align*}
    l  &= -\sum_{i=1}^{m} \Big(\frac{1}{2} \frac{(y_i - h_w(x_i))^2}{\sigma_i^2} \Big)
\end{align*}
We can see here that maximizing this quantity is equivalent to minimizing
\begin{align*}
    l  &= \sum_{i=1}^{m} \Big(\frac{1}{2} \frac{(y_i - h_w(x_i))^2}{\sigma_i^2} \Big)
\end{align*}
Assuming our hypothesis is a linear classifier $h_w(X) = Xw$
\begin{align*}
    l &= \sum_{i=1}^{m} \Big(\frac{1}{2} \frac{(y_i - x_i \cdot w)^2}{\sigma_i^2} \Big)\\
\end{align*} 
We can get the following by writing our expression in matrix form, letting $\mathbf{\sigma}$ be
a diagonal matrix containing with entries $\frac{1}{\sigma_i}$.  
\begin{align*}
    l &= \Big((Xw - y)^T \mathbf{\sigma} (y - Xw) \Big)\\
\end{align*}
Expanding, 
\begin{align*}
    l &= \Big((Xw - y)^T \mathbf{\sigma} (Xw - y) \Big)\\
      &= \Big((w^T X^T \mathbf{\sigma} - y^T \mathbf{\sigma})(Xw - y) \Big)\\
      &= \Big((w^T X^T \mathbf{\sigma} Xw - y^T \mathbf{\sigma} Xw - w^T X^T \mathbf{\sigma}y + y^T \mathbf{\sigma} y) \Big)\\
\end{align*}
Finally taking a gradient
\begin{align*}
    \vec\nabla_{w} l &= 2 X^T \sigma X w - 2X^T \sigma Y  \\ 
\end{align*}
Setting to zero, 
\begin{gather*}
     0 = 2 X^T \sigma X w - 2X^T \sigma Y  \\ 
     0 =  X^T \sigma X w - X^T \sigma Y  \\ 
     X^T \sigma X w = X^T \sigma Y  \\ 
      w = (X^T \sigma X)^{-1} X^T \sigma Y  \\ 
\end{gather*}

This can be intepreted as a type of weighted least squares. 

\begin{problem}{3. (a)}
Given the loss function as defined
\[
        L_H(w,\delta) = 
                \begin{cases} 
                (y_i - w^T x_i)^2 / 2 ,  \text{if} \mid y_i - w^T x_i y \mid \leq \delta \\ 
                \delta \mid  y_i - w^T x_i  \mid - \delta^2 /2, \text{otherwise}
                \end{cases}
\]
\end{problem}

As we have a piecewise loss function, we will also have a piece-wise gradient.
\[
        \vec \nabla_w L_H(w,\delta) = 
                \begin{cases} 
                (y_i - w^T x_i) x_i ,  \text{if} \mid y_i - w^T x_i y \mid \leq \delta \\ 
                \text{sign}(-y_i + w^T x_i)x_i , \text{otherwise} 
                \end{cases}
\]

\begin{problem}{3. (b)}
\end{problem}
To optimize this loss, we can just use a gradient based method getting the gradient for
each example and averaging the entire gradient for each update.

\begin{problem}{3. (c)}
See code
\end{problem}

\begin{problem}{4.}
Taking the hypothesis to be the product of those basis functions as provided
\end{problem}
Writing out the likelihood function:
\[
    L = \prod_{i=1}^{m} P(y_i \mid x_i ; h ) P(x_i)
\]
Again, taking the log and and dropping the $P(x_i)$ term. Assuming we are in the same settings
(regression, gaussian noising), using the form of the hypothesis suggested.
\begin{align*}
    l &= \sum_{i=1}^{m} \log ( \frac{1}{\sqrt{2\pi\sigma_i^2}} \exp \Big(-\frac{1}{2} \frac{(y_i - h_w(x_i))^2}{\sigma_i^2} \Big))) \\
      &= -\sum_{i=1}^{m} \Big(\frac{1}{2} \frac{(y_i - \prod_k^K \phi_k(x) )^2}{\sigma^2} \Big) \\
      &= -\sum_{i=1}^{m} \Big(\frac{1}{2} \frac{(y_i - \prod_k^K \exp(w_k^T \cdot x) )^2}{\sigma^2} \Big)\\
\end{align*}
Taking a derivative, 
\begin{align*}
    \vec\nabla_{w_k} l  &= -\sum_{i=1}^{m} \Big(\frac{1}{2} \frac{(y_i - \prod_k^K \exp(w_k^T \cdot x))}{\sigma^2} \cdot x  \Big)\\ 
\end{align*}

We can use a gradient based update to for each of the basis functions to optimize the value of this function.

% --------------------------------------------------------------
%     You don't have to mess with anything below this line.
% --------------------------------------------------------------

\end{document}
